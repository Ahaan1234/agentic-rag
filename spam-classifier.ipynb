{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377e468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in ./.venv/lib/python3.13/site-packages (0.6.1)\n",
      "Requirement already satisfied: langchain_openai in ./.venv/lib/python3.13/site-packages (0.3.28)\n",
      "Requirement already satisfied: langfuse in ./.venv/lib/python3.13/site-packages (3.2.1)\n",
      "Requirement already satisfied: smolagents[types] in ./.venv/lib/python3.13/site-packages (1.20.0)\n",
      "Requirement already satisfied: langchain-core>=0.1 in ./.venv/lib/python3.13/site-packages (from langgraph) (0.3.70)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in ./.venv/lib/python3.13/site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in ./.venv/lib/python3.13/site-packages (from langgraph) (0.6.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in ./.venv/lib/python3.13/site-packages (from langgraph) (0.2.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./.venv/lib/python3.13/site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.13/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./.venv/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./.venv/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in ./.venv/lib/python3.13/site-packages (from langchain_openai) (1.97.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.13/site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in ./.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in ./.venv/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.4)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./.venv/lib/python3.13/site-packages (from langfuse) (2.2.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in ./.venv/lib/python3.13/site-packages (from langfuse) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp<2.0.0,>=1.33.1 in ./.venv/lib/python3.13/site-packages (from langfuse) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in ./.venv/lib/python3.13/site-packages (from langfuse) (1.36.0)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in ./.venv/lib/python3.13/site-packages (from langfuse) (1.17.2)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.36.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.36.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (1.36.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in ./.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.36.0->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.66.2 in ./.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.36.0->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (1.73.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.36.0->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.36.0->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (1.36.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-proto==1.36.0->opentelemetry-exporter-otlp-proto-grpc==1.36.0->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse) (0.57b0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n",
      "\u001b[33mWARNING: smolagents 1.20.0 does not provide the extra 'types'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: huggingface-hub>=0.31.2 in ./.venv/lib/python3.13/site-packages (from smolagents[types]) (0.33.4)\n",
      "Requirement already satisfied: rich>=13.9.4 in ./.venv/lib/python3.13/site-packages (from smolagents[types]) (14.0.0)\n",
      "Requirement already satisfied: jinja2>=3.1.4 in ./.venv/lib/python3.13/site-packages (from smolagents[types]) (3.1.6)\n",
      "Requirement already satisfied: pillow>=10.0.1 in ./.venv/lib/python3.13/site-packages (from smolagents[types]) (11.3.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (from smolagents[types]) (1.1.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.31.2->smolagents[types]) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.31.2->smolagents[types]) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.31.2->smolagents[types]) (1.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2>=3.1.4->smolagents[types]) (3.0.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich>=13.9.4->smolagents[types]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=13.9.4->smolagents[types]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents[types]) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph langchain_openai langfuse \"smolagents[types]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be38331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from smolagents import LiteLLMModel\n",
    "from langchain.schema import BaseMessage, ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9ff92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailState(TypedDict):\n",
    "    email: Dict[str, Any]\n",
    "    is_spam: Optional[bool]\n",
    "    spam_reason: Optional[str]\n",
    "    email_category: Optional[str]\n",
    "    email_draft: Optional[str]\n",
    "    messages: List[Dict[str, Any]]\n",
    "\n",
    "model = LiteLLMModel(\n",
    "    model_id=\"gemini/gemini-2.0-flash-lite\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b809f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_email(state: EmailState):\n",
    "    \"\"\"Agent reads and logs the incoming email\"\"\"\n",
    "    email = state['email']\n",
    "    # Here we might do some initial preprocessing\n",
    "    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
    "\n",
    "    return{}\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    \"\"\"Agent uses an LLM to determine whether an email is spam or legitamate\"\"\"\n",
    "    e = state[\"email\"]\n",
    "\n",
    "    # Ask for structured output to make parsing robust and avoid substring traps.\n",
    "    prompt = f\"\"\"\n",
    "    You are an email triage agent. Read the email and return a JSON object with:\n",
    "    - \"is_spam\": true|false\n",
    "    - \"spam_reason\": string or null\n",
    "    - \"category\": one of [\"inquiry\",\"complaint\",\"thank-you\",\"request\",\"info\"] or null\n",
    "\n",
    "    Email:\n",
    "    From: {e['sender']}\n",
    "    Subject: {e['subject']}\n",
    "    Body: {e['body']}\n",
    "    Return JSON only.\n",
    "    \"\"\".strip()\n",
    "\n",
    "    messages = [\n",
    "        ChatMessage(role=\"user\", content=prompt)\n",
    "    ]\n",
    "\n",
    "    resp = model.generate(messages)\n",
    "    text = resp.content.strip()\n",
    "\n",
    "    import json\n",
    "    parsed = {\"is_spam\": None, \"spam_reason\": None, \"category\": None}\n",
    "    try:\n",
    "        parsed = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        # Minimal fallback heuristic if model ever fails JSON\n",
    "        lower = text.lower()\n",
    "        is_spam = (\"not spam\" not in lower) and (\"spam\" in lower)\n",
    "        reason = None\n",
    "        if is_spam and \"reason\" in lower:\n",
    "            try:\n",
    "                reason = lower.split(\"reason\", 1)[1].split(\"\\n\", 1)[0].strip(\": -\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        cat = None\n",
    "        for c in [\"inquiry\", \"complaint\", \"thank-you\", \"request\", \"info\"]:\n",
    "            if c in lower:\n",
    "                cat = c\n",
    "                break\n",
    "        parsed = {\"is_spam\": is_spam, \"spam_reason\": reason, \"category\": cat}\n",
    "\n",
    "\n",
    "    is_spam = bool(parsed.get(\"is_spam\"))\n",
    "    email_category = parsed.get(\"category\")\n",
    "    spam_reason = parsed.get(\"spam_reason\")\n",
    "    new_msgs = state[\"messages\"] + [\n",
    "        ChatMessage(role=\"user\",      content=prompt),\n",
    "        ChatMessage(role=\"assistant\", content=resp.content),\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"is_spam\": is_spam,\n",
    "        \"spam_reason\": spam_reason,\n",
    "        \"email_category\": email_category,\n",
    "        \"messages\": new_msgs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2c9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_spam(state: EmailState):\n",
    "    \"\"\"Agent discards spam email with a note\"\"\"\n",
    "    print(f\"Agent has marked the email as spam. Reason: {state['spam_reason']}\")\n",
    "    print(\"The email has been moved to the spam folder.\")\n",
    "    \n",
    "    return {}\n",
    "\n",
    "def draft_response(state: EmailState):\n",
    "    \"\"\"Agent drafts a preliminary response for legitimate emails\"\"\"\n",
    "    e = state[\"email\"]\n",
    "    category = state.get(\"email_category\") or \"general\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Draft a brief, polite, professional reply to the email below.\n",
    "    Assume category: {category}.\n",
    "    Return only the draft reply text (no JSON).\n",
    "\n",
    "    From: {e['sender']}\n",
    "    Subject: {e['subject']}\n",
    "    Body: {e['body']}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    resp = model.generate([{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "    new_msgs = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": resp.content},\n",
    "    ]\n",
    "    return {\"email_draft\": resp.content, \"messages\": new_msgs}\n",
    "\n",
    "def notify_me(state: EmailState):\n",
    "    \"\"\"\n",
    "    Notify me when an email comes in along with its classification\n",
    "    \"\"\"\n",
    "    e = state[\"email\"]\n",
    "    print(f\"\\nSir, new mail from {e['sender']} ({state['email_category']})\")\n",
    "    print(state[\"email_draft\"])\n",
    "    return {}\n",
    "\n",
    "def route_email(state: EmailState) -> str:\n",
    "    return \"spam\" if state[\"is_spam\"] else \"legitimate\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fa5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = StateGraph(EmailState)\n",
    "\n",
    "g.add_node(\"read_email\", read_email)\n",
    "g.add_node(\"classify_email\", classify_email)\n",
    "g.add_node(\"handle_spam\", handle_spam)\n",
    "g.add_node(\"draft_response\", draft_response)\n",
    "g.add_node(\"notify_mr_wayne\", notify_me)\n",
    "\n",
    "g.add_edge(START, \"read_email\")\n",
    "g.add_edge(\"read_email\", \"classify_email\")\n",
    "g.add_conditional_edges(\"classify_email\", route_email,{\"spam\": \"handle_spam\", \"legitimate\": \"draft_response\"})\n",
    "g.add_edge(\"handle_spam\", END)\n",
    "g.add_edge(\"draft_response\", \"notify_mr_wayne\")\n",
    "g.add_edge(\"notify_mr_wayne\", END)\n",
    "\n",
    "mail_bot = g.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "744b3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit = {\n",
    "    \"sender\": \"john.smith@example.com\",\n",
    "    \"subject\": \"Question about your services\",\n",
    "    \"body\": \"Dear Mr Wayne, I was referred by a colleague â€¦\"\n",
    "}\n",
    "spam = {\n",
    "    \"sender\": \"winner@lottery-intl.com\",\n",
    "    \"subject\": \"YOU HAVE WON $5,000,000!!!\",\n",
    "    \"body\": \"CONGRATULATIONS! Click hereâ€¦\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced40a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘‰ Legitimate mail\n",
      "Alfred is processing an email from john.smith@example.com with subject: Question about your services\n",
      "Agent has marked the email as spam. Reason: \": null,\n",
      "The email has been moved to the spam folder.\n",
      "\n",
      "ðŸ‘‰ Spam mail\n",
      "Alfred is processing an email from winner@lottery-intl.com with subject: YOU HAVE WON $5,000,000!!!\n",
      "Agent has marked the email as spam. Reason: \": \"lottery/scam\",\n",
      "The email has been moved to the spam folder.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'email': {'sender': 'winner@lottery-intl.com',\n",
       "  'subject': 'YOU HAVE WON $5,000,000!!!',\n",
       "  'body': 'CONGRATULATIONS! Click hereâ€¦'},\n",
       " 'is_spam': True,\n",
       " 'spam_reason': '\": \"lottery/scam\",',\n",
       " 'email_category': None,\n",
       " 'email_draft': None,\n",
       " 'messages': [ChatMessage(content='You are an email triage agent. Read the email and return a JSON object with:\\n    - \"is_spam\": true|false\\n    - \"spam_reason\": string or null\\n    - \"category\": one of [\"inquiry\",\"complaint\",\"thank-you\",\"request\",\"info\"] or null\\n\\n    Email:\\n    From: winner@lottery-intl.com\\n    Subject: YOU HAVE WON $5,000,000!!!\\n    Body: CONGRATULATIONS! Click hereâ€¦\\n    Return JSON only.', additional_kwargs={}, response_metadata={}, role='user'),\n",
       "  ChatMessage(content='```json\\n{\\n  \"is_spam\": true,\\n  \"spam_reason\": \"Lottery/Scam\",\\n  \"category\": null\\n}\\n```', additional_kwargs={}, response_metadata={}, role='assistant')]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ðŸ‘‰ Legitimate mail\")\n",
    "mail_bot.invoke({\n",
    "    \"email\": legit,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"email_draft\": None,\n",
    "    \"messages\": [],\n",
    "})\n",
    "\n",
    "print(\"\\nðŸ‘‰ Spam mail\")\n",
    "# IMPORTANT: pass the state again\n",
    "mail_bot.invoke({\n",
    "    \"email\": spam,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"email_draft\": None,\n",
    "    \"messages\": [],\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
