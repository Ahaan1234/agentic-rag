{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a456e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading PDFs: 100%|██████████| 13/13 [00:11<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "PDF_DIR = pathlib.Path(\"data/raw\")\n",
    "pdf_paths = sorted(PDF_DIR.glob(\"*.pdf\"))\n",
    "assert pdf_paths, \"No PDFs found - check path\"\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader, PyPDFLoader\n",
    "from langchain.docstore.document import Document\n",
    "from tqdm import tqdm\n",
    "\n",
    "source_docs = []\n",
    "\n",
    "for path in tqdm(pdf_paths, desc=\"Reading PDFs\"):\n",
    "    try:\n",
    "        loader = PyPDFLoader(str(path))\n",
    "        pages = list(loader.lazy_load())\n",
    "    except Exception as e:\n",
    "        print(f\"Failed at {path.name}: {e}\")\n",
    "        continue\n",
    "    for p in pages:\n",
    "        # Unstructured returns one Document per page by default\n",
    "        p.metadata[\"source\"] = path.stem                 # short source name\n",
    "        p.metadata[\"page_num\"] = p.metadata.get(\"page\")  # keep original page index\n",
    "    source_docs.extend(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d335d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for d in source_docs :\n",
    "    txt = d.page_content\n",
    "    txt = re.sub(r\"\\s+\\n\", \"\\n\", txt)\n",
    "    txt = re.sub(r\"\\n{3,}\", \"\\n\\n\", txt)\n",
    "    d.page_content = txt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b03ef5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d98464caf74f77b09c577168d60f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286a3058768e43178613638b0d33bb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22cc38703e7b4442a63000400b4f92d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5388382784c04aabbdc25b0cd6830998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting and deduplicating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [00:03<00:00, 137.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "spliiter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    AutoTokenizer.from_pretrained(\"thenlper/gte-small\"),\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap=20,\n",
    "    add_start_index = True,\n",
    "    strip_whitespace = True\n",
    ")\n",
    "\n",
    "print(\"Splitting and deduplicating...\")\n",
    "\n",
    "docs_processed, seen = [], set()\n",
    "\n",
    "for doc in tqdm(source_docs) :\n",
    "    for chunk in spliiter.split_documents([doc]):\n",
    "        if chunk.page_content not in seen:\n",
    "            seen.add(chunk.page_content)\n",
    "            docs_processed.append(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7850f0",
   "metadata": {},
   "source": [
    "The above block is used to process raw text content into FAISS's expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "{'producer': 'iLovePDF', 'creator': 'Acrobat PDFMaker 11 for Word', 'creationdate': '2023-12-06T15:01:50+05:30', 'author': 'Amol Dighe', 'company': '', 'sourcemodified': 'D:20231206092752', 'subject': 'A Roadmap prepared by the Indian Nuclear Physics Communitywith TIFR, Mumbai as the Nodal Scientific Institution', 'title': 'Mega Science Vision – 2035   Nuclear Physics', 'moddate': '2024-01-24T10:12:18+00:00', 'source': 'DST - MSV2035-NP-Final', 'total_pages': 140, 'page': 14, 'page_label': '15', 'page_num': 14, 'start_index': 0}\n",
      "MEGA SCIENCE VISION – 2035   NUCLEAR PHYSICS\n",
      "3\n",
      "THE DRAFTING AND WO RKING GROUPS\n",
      "Director TIFR, Mumbai –\n",
      "Dr. Jayaram Chengalur / Dr. S. Ramakrishnan / Dr. Sandip Trivedi Chairperson\n",
      "Members from the D rafting Group\n",
      "Dr. Alphonsa Joseph Palakkel, IPR, Gandhinagar Member\n",
      "Dr. Aradhana Srivastava, BARC, Mumbai Member\n",
      "Dr. Bedangadas Mohanty, NISER, Bhubaneswar Member\n",
      "Dr. Rudrajyoti Palit, TIFR, Mumbai Member\n",
      "Other expert members\n",
      "Dr. Akhil Jhingan, IUAC, New Delhi Member\n",
      "Dr. Javed A. Sheikh, Kashmir University, Srinagar Member\n",
      "Dr. Lokesh Kumar, Panjab University, Chandigarh Member\n",
      "Dr. P. K. Atrey, IPR, Gandhinagar Member\n",
      "Dr. Rajdeep Chatterjee, IIT-Roorkee Member\n"
     ]
    }
   ],
   "source": [
    "## SANITY CHECK - MAKE SURE THAT OUR CODE WORKED AND DOCUMENTS WERE CREATED\n",
    "\n",
    "doc = docs_processed[15]\n",
    "print(type(doc))\n",
    "print(doc.metadata)\n",
    "print(doc.page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6905f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/mz642z_s78s28vthdq18syww0000gn/T/ipykernel_19800/2057286766.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Duke/ECs/summer-25/agentic-rag/.venv/lib/python3.13/site-packages/langchain_community/embeddings/huggingface.py:84\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sentence_transformers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistanceStrategy\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m embed = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthenlper/gte-small\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m vector_db = FAISS.from_documents(docs_processed, embedding=embed, distance_strategy = DistanceStrategy.COSINE)\n\u001b[32m      9\u001b[39m FAISS.save_local(vector_db, \u001b[33m\"\u001b[39m\u001b[33mdata/processed/faiss_index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Duke/ECs/summer-25/agentic-rag/.venv/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:222\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    220\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    221\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Duke/ECs/summer-25/agentic-rag/.venv/lib/python3.13/site-packages/langchain_community/embeddings/huggingface.py:87\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import sentence_transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     90\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.client = sentence_transformers.SentenceTransformer(\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_name, cache_folder=\u001b[38;5;28mself\u001b[39m.cache_folder, **\u001b[38;5;28mself\u001b[39m.model_kwargs\n\u001b[32m     94\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "embed = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "\n",
    "vector_db = FAISS.from_documents(docs_processed, embedding=embed, distance_strategy = DistanceStrategy.COSINE)\n",
    "\n",
    "FAISS.save_local(vector_db, \"data/processed/faiss_index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
